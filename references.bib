@article{PreTrainedTransformer,
  doi = {10.48550/ARXIV.1908.08345},
  url = {https://arxiv.org/abs/1908.08345},
  author = {Liu, Yang and Lapata, Mirella},
  title = {Text Summarization with Pretrained Encoders},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Einstein1905,
  author = {Einstein, Albert},
  title = {Zur Elektrodynamik bewegter K{\"o}rper},
  journal = {Annalen der Physik},
  volume = {17},
  number = {10},
  pages = {891--921},
  year = {1905},
  publisher = {Wiley-VCH}
}

@article{TrainTransformerm,
  author = {Cristina, Stefania},
  title = {Training the Transformer Model},
  url = {https://machinelearningmastery.com/training-the-transformer-model/},
  year = {2022},
  month = {october},
  day = {6}
}

@article{Whatisattention,
  author = {Cristina, Stefania},
  title = {What Is Attention?},
  url = {https://arxiv.org/abs/1706.03762},
  year = {2017},
  month = {June},
  day = {12}
}

@article{attentioniayn,
  author = {Ashish {Vaswani} and Noam {Shazeer}and Niki {Parmar} and Jakob {Uszkoreit}and Llion {Jones}and Aidan N. {Gomez}and Lukasz {Kaiser}and Illia {Polosukhin}},
  title = {Attention Is All You Need},
  url = {https://machinelearningmastery.com/what-is-attention/},
  year = {2022},
  month = {August},
  day = {25}
}

@article{Traintips,
  author = {Martin {Popel} and Ond≈ôej {Bojar}},
  title = {Training Tips for the Transformer Model},
  url = {https://arxiv.org/abs/1804.00247},
  journal = {The Prague Bulletin of Mathematical Linguistics},
  pages = {67},
  year = {2018},
  month = {April},
  day = {2}
}

@article{JMLR,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929--1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@article{ComprehensiveGuide,
  author  = {Aravindpai Pai},
  title   = {Comprehensive Guide to Text Summarization using Deep Learning in Python},
  year    = {2020},
  month = {may},
  day = {10},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@misc{tensorflow2015-whitepaper,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}